# é›†ç¾¤æ­å»º

<!-- TOC -->

- [é›†ç¾¤æ­å»º](#é›†ç¾¤æ­å»º)
    - [ç³»ç»Ÿå‡†å¤‡ï¼ˆé’ˆå¯¹Vmwareï¼‰](#ç³»ç»Ÿå‡†å¤‡é’ˆå¯¹vmware)
    - [å®‰è£…Linuxï¼ˆCentOs6.8ï¼‰](#å®‰è£…linuxcentos68)
    - [ç¯å¢ƒå¸ƒç½®](#ç¯å¢ƒå¸ƒç½®)
    - [è½¯ä»¶å‡†å¤‡](#è½¯ä»¶å‡†å¤‡)
    - [Hadoop é›†ç¾¤æ­å»º](#hadoop-é›†ç¾¤æ­å»º)
        - [è™šæ‹Ÿæœºå‡†å¤‡](#è™šæ‹Ÿæœºå‡†å¤‡)

<!-- /TOC -->
---

## ç³»ç»Ÿå‡†å¤‡ï¼ˆé’ˆå¯¹Vmwareï¼‰

- è‡ªå®šä¹‰å®‰è£…
- ç¨åå®‰è£…æ“ä½œç³»ç»Ÿ

- å¤„ç†å™¨ï¼ˆ2æ ¸4çº¿ç¨‹ï¼‰æ ¸æ•°ï¼š2ï¼›æ¯ä¸ªå¤„ç†å™¨å†…æ ¸æ•°ï¼š2
- å†…å­˜ï¼š3G
- ç½‘ç»œç±»å‹ï¼šNAT
- I/Oæ§åˆ¶å™¨ï¼šLSI Logic
- ç£ç›˜ç±»å‹ï¼šSCSI
- ç£ç›˜ï¼šåˆ›å»ºæ–°è™šæ‹Ÿç£ç›˜
- ç£ç›˜å¤§å°ï¼š40Gï¼ˆå­˜å‚¨ä¸ºå•ä¸ªæ–‡ä»¶ï¼‰

## å®‰è£…Linuxï¼ˆCentOs6.8ï¼‰

- åˆ›å»ºè‡ªå®šä¹‰å¸ƒå±€

- æ ‡å‡†åˆ†åŒº

  /boot 200M

  swap 2G

  ![1561552597540](assets\1561552597540.png)

  /	å‰©ä¸‹

  ![1561552628903](assets\1561552628903.png)

- é€‰æ‹©æœ€å°å®‰è£…ï¼šMinimal

  ![1561552712936](assets\1561552712936.png)

## ç¯å¢ƒå¸ƒç½®

- æ£€æŸ¥æ˜¯å¦è”ç½‘ï¼š`ifconfig`æŸ¥çœ‹inetæ˜¯å¦è·å–åˆ°IP

- é€šè¿‡[éƒ¨ç½²è„šæœ¬](data/deploy.sh)å®ŒæˆåŸºæœ¬é…ç½®

  - æ›´æ–°yumæº
  
    > 1. ç”¨çš„æ˜¯[æ¸…åé•œåƒæº](https://mirror.tuna.tsinghua.edu.cn/help/centos/)
    >
    > 2. å¤‡ä»½CentOS-Base.repo
    >
    >       cp /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak
    >
    > 3. ä¿®æ”¹CentOS-Base.repo
    >
    >       æ‹·è´å¯¹åº”ç³»ç»Ÿç‰ˆæœ¬åˆ°CentOS-Base.repo
  
  - é…ç½®vim
  
  - ä¼˜åŒ–xshellè¿æ¥
  
  - å…³é—­é˜²ç«å¢™
  
  - æ›´æ”¹hosts
  
  - é…ç½®JAVA_HOMEå’ŒHADOOP_HOME
  
  - å®‰è£…zshå’Œoh-my-zsh
  
- é€šè¿‡[è™šæ‹Ÿæœºé…ç½®è„šæœ¬](data/modify.sh)å®Œæˆç½‘ç»œé…ç½®

  - ä¿®æ”¹hostname
  - ä¿®æ”¹IP
  - ä¿®æ”¹ç½‘å¡è„šæœ¬

- åˆ›å»ºä¸€èˆ¬ç”¨æˆ·hadoopå¹¶èµ‹äºˆsudoæƒé™

  ```
  useradd hadoop
  passwd hadoop
  vim /etc/sudoers
  	åœ¨root ALL=(ALL) ALL ä¸€è¡Œåæ·»åŠ 
  	hadoop ALL=(ALL) NOPASSWD:ALL
  ```

- åœ¨/optç›®å½•ä¸‹åˆ›å»ºmoduleå’Œsoftwareæ–‡ä»¶å¤¹ï¼Œå¹¶ç»™hadoopèµ‹äºˆæ‰€æœ‰æƒ

  ```
  mkdir /opt/module /opt/software
  chown hadoop:hadoop /opt/module /opt/software
  ```
  
- é‡å¯ï¼Œé€šè¿‡[xshell](https://www.lanzous.com/i1t4rne)ç™»å½•hadoopç”¨æˆ·

- å®‰è£…[JDK](https://www.oracle.com/technetwork/java/javase/downloads/java-archive-javase8-2177648.html):

  è§£å‹jdk-8u144-linux-x64.tar.gzåˆ°ç›®å½•/opt/module/

  â€‹	`tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module/`

## è½¯ä»¶å‡†å¤‡

1. [JDK](https://www.oracle.com/technetwork/java/javase/downloads/java-archive-javase8-2177648.html) ï¼šjdk-8u144-linux-x64
2. [Hadoop](https://hadoop.apache.org/release/2.7.2.html)ï¼šhadoop-2.7.2
3. [Zookeeper](https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz)ï¼šzookeeper-3.4.14

## è„šæœ¬å‡†å¤‡

1. [éƒ¨ç½²è„šæœ¬]ï¼šdeploy
2. [å…‹éš†è™šæ‹Ÿæœºé…ç½®è„šæœ¬](data/modify.sh):modify
3. [é›†ç¾¤åˆ†å‘è„šæœ¬](data/xsync.sh):xsync
4. [é›†ç¾¤è¿›ç¨‹æŸ¥çœ‹è„šæœ¬](data/jpsall):jpsall
5. [zookeeperç¾¤èµ·è„šæœ¬]ï¼šzkstartall
6. [zookeeperçŠ¶æ€æŸ¥è¯¢è„šæœ¬]ï¼šzkstatus
7. [zookeeperç¾¤å…³è„šæœ¬]ï¼šzkstopall

## Hadoop é›†ç¾¤æ­å»º

### è™šæ‹Ÿæœºå‡†å¤‡

1. å…‹éš†ä¸¤å°è™šæ‹Ÿæœºï¼Œé€šè¿‡[è„šæœ¬](data/modify.sh)æ›´æ”¹hostnameã€IPã€ç½‘å¡è„šæœ¬

2. å‡†å¤‡é›†ç¾¤[åˆ†å‘è„šæœ¬](data/xsync.sh)

   ```
   chmod +x xsyc	# æ·»åŠ æ‰§è¡Œæƒé™
   sudo cp xsync /bin	#è®©è„šæœ¬å…¨å±€å¯ç”¨
   sudo cp xsync /usr/local/bin
   ```

3. å‡†å¤‡é›†ç¾¤[è¿›ç¨‹æŸ¥çœ‹è„šæœ¬](data/jpsall)

4. é…ç½®sshå…å¯†ç™»å½•

   ```bash
   # hadoop @ hadoop101 in ~ [19:02:34] C:255
   $ ssh-keygen -t rsa (æ•²ä¸‰æ¬¡å›è½¦)
   # å‘é€å¯†ç åˆ°æœ¬æœº
   # hadoop @ hadoop101 in ~ [19:03:18] 
   $ ssh-copy-id hadoop101 ï¼ˆyes/è¾“å…¥ä¸€æ¬¡å¯†ç ï¼‰
   
   # åˆ†åˆ«sshç™»é™†ä¸€ä¸‹æ‰€æœ‰è™šæ‹Ÿæœº
   ssh hadoop102
   exit
   ssh hadoop103
   exit
   
   # æŠŠ/home/hadoop/.ssh æ–‡ä»¶å¤¹å‘é€åˆ°é›†ç¾¤æ‰€æœ‰æœåŠ¡å™¨
   # hadoop @ hadoop101 in ~ [19:16:54] C:1
   $ xsync /home/hadoop/.ssh/
   ```

### é›†ç¾¤è§„åˆ’

|      | hadoop101           | hadoop102                     | hadoop103                    |
| :--: | :------------------ | :---------------------------- | :--------------------------- |
| HDFS | NameNode   DataNode | DataNode                      | SecondaryNameNode   DataNode |
| YARN | NodeManager         | ResourceManager   NodeManager | NodeManager                  |

1. ä¿®æ”¹é›†ç¾¤é…ç½®æ–‡ä»¶ï¼ˆ[å®˜æ–¹é…ç½®æ–‡æ¡£](https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/ClusterSetup.html)ï¼‰

```xml
# è¿›å…¥ç›®å½•/opt/module/hadoop-2.7.2/etc/hadoop
1. ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼ˆæ·»åŠ ä»¥ä¸‹å†…å®¹ï¼‰
	1ï¼‰ core-site.xml
		<!-- æŒ‡å®šHDFSä¸­NameNodeçš„åœ°å€ -->
		<property>
			<name>fs.defaultFS</name>
      		<value>hdfs://hadoop101:9000</value>
		</property>

		<!-- æŒ‡å®šHadoopè¿è¡Œæ—¶äº§ç”Ÿæ–‡ä»¶çš„å­˜å‚¨ç›®å½• -->
		<property>
			<name>hadoop.tmp.dir</name>
			<value>/opt/module/hadoop-2.7.2/data/tmp</value>
		</property>
	2ï¼‰ hadoop-env.sh
		export JAVA_HOME=/opt/module/jdk1.8.0_144
	3ï¼‰ hdfs-site.xml
		<!-- æŒ‡å®šå‰¯æœ¬æ•° -->
		<property>
			<name>dfs.replication</name>
			<value>3</value>
		</property>

		<!-- æŒ‡å®šSecondaryNameNodeèŠ‚ç‚¹ä¸»æœº -->
		<property>
      		<name>dfs.namenode.secondary.http-address</name>
      		<value>hadoop103:50090</value>
		</property>
	4ï¼‰ yarn-env.sh
		export JAVA_HOME=/opt/module/jdk1.8.0_144
	5ï¼‰ yarn-site.xml
		<!-- Reducerè·å–æ•°æ®çš„æ–¹å¼ -->
		<property>
			<name>yarn.nodemanager.aux-services</name>
			<value>mapreduce_shuffle</value>
		</property>

		<!-- æŒ‡å®šYARNçš„ResourceManagerçš„åœ°å€ -->
		<property>
			<name>yarn.resourcemanager.hostname</name>
			<value>hadoop102</value>
		</property>

		<!-- æ—¥å¿—èšé›†åŠŸèƒ½ä½¿èƒ½ -->
        <property>
        	<name>yarn.log-aggregation-enable</name>
        	<value>true</value>
        </property>

        <!-- æ—¥å¿—ä¿ç•™æ—¶é—´è®¾ç½®7å¤© -->
        <property>
        	<name>yarn.log-aggregation.retain-seconds</name>
        	<value>604800</value>
        </property>
	6ï¼‰ mapred-env.sh
		export JAVA_HOME=/opt/module/jdk1.8.0_144
	7ï¼‰ cp mapred-site.xml.template mapred-site.xml && vim mapred-site.xml
		<!-- æŒ‡å®šMRè¿è¡Œåœ¨Yarnä¸Š -->
		<property>
			<name>mapreduce.framework.name</name>
			<value>yarn</value>
		</property>
		<!-- å†å²æœåŠ¡å™¨ç«¯åœ°å€-->
        <property>
        	<name>mapreduce.jobhistory.address</name>
        	<value>hadoop101:10020</value>
        </property>
        <!-- å†å²æœåŠ¡å™¨webç«¯åœ°å€-->
        <property>
        	<name>mapreduce.jobhistory.webapp.address</name>
        	<value>hadoop101:19888</value>
        </property>
	8ï¼‰ é…ç½®slaves
		hadoop101
		hadoop102
		hadoop103

2. åˆ†å‘é…ç½®æ–‡ä»¶
	# hadoop @ hadoop101 in /opt/module/hadoop-2.7.2/etc [19:42:03] 
	$ xsync hadoop
```

### é›†ç¾¤æ“ä½œ

1. å¯åŠ¨é›†ç¾¤

   ```
   1. ç¬¬ä¸€æ¬¡å¯åŠ¨ï¼Œæ ¼å¼åŒ–NameNode
   	hdfs namenode -format
   	æˆåŠŸæç¤ºï¼š
   	INFO common.Storage: Storage directory /opt/module/hadoop-2.7.2/data/tmp/dfs/name has been successfully formatted.
   2. å¯åŠ¨HDFS(åœ¨hadoop101)
   	satrt-dfs.sh
   	æˆåŠŸæç¤ºï¼š
   	# hadoop @ hadoop101 in /opt/module/hadoop-2.7.2 [19:59:09] 
   	$ jpsall
   	======================= hadoop101 =============================
   	3619 NameNode
   	3742 DataNode
   	======================= hadoop102 =============================
   	2175 DataNode
   	======================= hadoop103 =============================
   	1888 SecondaryNameNode
   	1821 DataNode
   3. å¯åŠ¨YARNï¼ˆåœ¨hadoop102ï¼‰
   	start-yarn.sh
   	æˆåŠŸæç¤ºï¼š
   	# hadoop @ hadoop101 in /opt/module/hadoop-2.7.2 [19:59:15] 
   	$ jpsall
   	======================= hadoop101 =============================
   	3619 NameNode
   	4042 NodeManager
   	3742 DataNode
   	======================= hadoop102 =============================
   	2323 ResourceManager
   	2421 NodeManager
   	2175 DataNode
   	======================= hadoop103 =============================
   	1888 SecondaryNameNode
   	2019 NodeManager
   	1821 DataNode
   ```

2. åœæ­¢é›†ç¾¤

   ```
   1. åœæ­¢HDFS
   	stop-dfs.sh
   2. åœæ­¢YARN
   	stop-yarn.sh
   ```

3. Webç«¯æŸ¥çœ‹é›†ç¾¤

   ```
   1. NameNode
   	http://hadoop101:50070
   2. YARN
   	http://hadoop102:8088
   3. Secondary NameNode
   	http://hadoop103:50090/status.html
   4. JobHistory
   	http://hadoop101:19888
   ```

4. é›†ç¾¤æ—¶é—´åŒæ­¥

   ```bash
   1. åˆ‡æ¢åˆ°rootç”¨æˆ·
   	su
   2.	ntpå’Œntpdateå®‰è£…
   	yum install -y ntp
   3. é…ç½®é›†ç¾¤æ—¶é—´æœåŠ¡å™¨ï¼ˆhadoop101ï¼‰
   	1ï¼‰æ‰‹åŠ¨è”ç½‘æ ¡æ—¶ 
   		a æŸ¥çœ‹ntpdæœåŠ¡
   			service ntpd status
   		b å…³é—­ntpdæœåŠ¡
   			service ntpd stop
   		c åŒæ­¥æ—¶é—´
   			ntpdate ntp1.aliyun.com
   	2) ä¿®æ”¹ntpé…ç½®æ–‡ä»¶
   		sudo vim /etc/ntp.conf
   		a æˆæƒ192.168.1.0-192.168.1.255ç½‘æ®µä¸Šçš„æ‰€æœ‰æœºå™¨å¯ä»¥ä»è¿™å°æœºå™¨ä¸ŠæŸ¥è¯¢å’ŒåŒæ­¥æ—¶é—´
   			restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap
   		b é›†ç¾¤æ˜¯åœ¨ä¸€ä¸ªå°é—­çš„å±€åŸŸç½‘å†…ï¼Œå¯ä»¥å±è”½æ‰é»˜è®¤çš„server:(å±è”½æ‰ä»¥å,é›†ç¾¤å†…éƒ¨æ—¶é—´ä¸€è‡´)
   		c å°†hadoop101çš„æœ¬åœ°æ—¶é’Ÿä½œä¸ºæ—¶é—´ä¾›ç»™æºï¼Œå³ä¾¿å®ƒå¤±å»ç½‘ç»œè¿æ¥ï¼Œå®ƒä¹Ÿå¯ä»¥ç»§ç»­ä¸ºç½‘ç»œæä¾›æœåŠ¡;
   			server 127.127.1.0
   			fudge 127.127.1.0 stratum 10
   	3ï¼‰ ç¡¬ä»¶æ—¶é—´ä¸ç³»ç»Ÿæ—¶é—´åŒæ­¥
   		vim /etc/sysconfig/ntpd
   		å¢åŠ å†…å®¹å¦‚ä¸‹
   		SYNC_HWCLOCK=yes
   	4ï¼‰ ç¡¬ä»¶æ—¶é—´å’Œç³»ç»Ÿæ—¶é—´åŒæ­¥
   		hwclock --systohc
   	5ï¼‰ é‡å¯ntpdæœåŠ¡
   		service ntpd start
   	6ï¼‰ è®¾ç½®ntpdæœåŠ¡å¼€æœºå¯åŠ¨
   		chkconfig ntpd on
   4. salveæ—¶é—´é…ç½®
   	1ï¼‰ è®¾ç½®æ—¶é—´æœåŠ¡å™¨hadoop101åŒæ­¥é¢‘ç‡ 10min/æ¬¡
   		crontab -e
   		è¾“å…¥å†…å®¹ï¼š
   			# ä¸æ—¶é—´æœåŠ¡å™¨hadoop104åŒæ­¥é¢‘ç‡ 10min/æ¬¡
   			*/10 * * * * /sbin/ntpdate hadoop101
   			# (30min/æ¬¡) å°†ç³»ç»Ÿæ—¶é—´åŒæ­¥ç»™ç¡¬ä»¶
   			*/30 * * * * /sbin/hwclock -w
   	2ï¼‰ åˆ·æ–°crontabæœåŠ¡
   		service crond restart
   	3ï¼‰ æ³¨é‡Š/etc/ntp.confä¸­çš„server
   	4ï¼‰ å¯åŠ¨ntpdæœåŠ¡
   		service ntpd restart
   ```

### Q&A

1. Q:å¯åŠ¨Hadoopé›†ç¾¤æç¤º**Host key verification failed.**

   A:åŸå› æ˜¯sshä¸­çš„keyç”±äºæŸäº›åŸå› ï¼ˆsshå…å¯†æ²¡åšå½»åº•é‡æ–°å…‹éš†è™šæ‹Ÿæœºï¼‰å¯¼è‡´ä¸åŒ¹é…ï¼Œé€ æˆæŸäº›èŠ‚ç‚¹æ— æ³•è¿æ¥ã€‚åªéœ€è¦å°†**æ¯ä¸ªèŠ‚ç‚¹çš„`.ssh`åˆ é™¤é‡æ–°åšä¸€æ¬¡sshå…å¯†å³å¯**ã€‚



## Zookeeper

 1. é›†ç¾¤è§„åˆ’

    åœ¨101ã€102ã€103ä¸Šéƒ¨ç½²Zookeeper

2. å®‰è£…

    å®‰è£…åŒ…å‡†å¤‡ï¼š[zookeeper-3.4.14](https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz)

    ```bash
    1. è§£å‹zookeeper-3.4.14åˆ°ç›®å½•/opt/module
    	tar -zxvf zookeeper-3.4.14.tar.gz -C /opt/module/
    2. åŒæ­¥/opt/module/zookeeper-3.4.14ç›®å½•å†…å®¹åˆ°hadoop102ã€hadoop103
    	xsync zookeeper-3.4.10/
    ```

3. é…ç½®æœåŠ¡å™¨ç¼–å·myid

    ```
    1. åœ¨/opt/module/zookeeper-3.4.14/è¿™ä¸ªç›®å½•ä¸‹åˆ›å»ºzkData
    	mkdir zkData 
    2. åœ¨/opt/module/zookeeper-3.4.14/zkDataè¿™ä¸ªç›®å½•ä¸‹åˆ›å»ºmyidæ–‡ä»¶
    	vim myid
    	è¾“å…¥å†…å®¹ï¼š
    	101
    3. åˆ†å‘zkDataåˆ°hadoop102ã€hadoop103.å¹¶æ›´æ”¹myidä¸ºå„è‡ªçš„id
    ```

4. é…ç½®zoo.cfg
	
	```
	1. é‡å‘½å/opt/module/zookeeper-3.4.10/confè¿™ä¸ªç›®å½•ä¸‹çš„zoo_sample.cfgä¸ºzoo.cfg
		cp zoo_sample.cfg zoo.cfg
	2. é…ç½®zoo.cfg
		vim zoo.cfg
		è¾“å…¥å†…å®¹ï¼š
		dataDir=/opt/module/zookeeper-3.4.10/zkData
		#######################cluster##########################
	    server.101=hadoop101:2888:3888
	    server.102=hadoop102:2888:3888
	    server.103=hadoop103:2888:3888
	3. åˆ†å‘é…ç½®æ–‡ä»¶
		xsync zoo.cfg
	```
	
5. é›†ç¾¤æ“ä½œ
	
	1. å¯åŠ¨
	
	   æ¯å°æœºå™¨é€æ­¥å¯åŠ¨
	
	   `/opt/module/zookeeper-3.4.14/bin/zkServer.sh start`
	
	   **[ç¾¤èµ·è„šæœ¬]**
	
	2. æŸ¥çœ‹çŠ¶æ€
	
	   æ¯å°æœºå™¨é€å°æŸ¥è¯¢
	
	   `/opt/module/zookeeper-3.4.14/bin/zkServer.sh status`
	
	   **[ç¾¤æŸ¥è„šæœ¬]**
	
	3. å…³é—­ğŸ‘‰[è„šæœ¬]
	
	4. å®¢æˆ·ç«¯å‘½ä»¤è¡Œæ“ä½œ
	
	   å¯åŠ¨zookeeperå®¢æˆ·ç«¯ï¼š/opt/module/zookeeper-3.4.10/bin/zkCli.sh
	   
	   | å‘½ä»¤åŸºæœ¬è¯­æ³•      | åŠŸèƒ½æè¿°                                               | ç¤ºä¾‹                 |
	   | ----------------- | ------------------------------------------------------ | -------------------- |
	   | help              | æ˜¾ç¤ºæ‰€æœ‰æ“ä½œå‘½ä»¤                                       |                      |
	   | ls path   [watch] | ä½¿ç”¨ ls å‘½ä»¤æ¥æŸ¥çœ‹å½“å‰znodeä¸­æ‰€åŒ…å«çš„å†…å®¹              | ls /                 |
	   | ls2 path [watch]  | æŸ¥çœ‹å½“å‰èŠ‚ç‚¹æ•°æ®å¹¶èƒ½çœ‹åˆ°æ›´æ–°æ¬¡æ•°ç­‰æ•°æ®                 | ls2 /                |
	   | create            | æ™®é€šåˆ›å»º   -s  å«æœ‰åºåˆ—   -e  ä¸´æ—¶ï¼ˆé‡å¯æˆ–è€…è¶…æ—¶æ¶ˆå¤±ï¼‰ | create -e /dir "tmp" |
	   | get path [watch]  | è·å¾—èŠ‚ç‚¹çš„å€¼                                           | get /dir tmp         |
	   | set               | è®¾ç½®èŠ‚ç‚¹çš„å…·ä½“å€¼                                       | set /dir "modify"    |
	   | stat              | æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€                                           | stat /dir            |
	   | delete            | åˆ é™¤èŠ‚ç‚¹                                               | delete /dir/dir1     |
	   | rmr               | é€’å½’åˆ é™¤èŠ‚ç‚¹                                           | rmr /dit             |
	
	
	
	## Flume
	
	1. é›†ç¾¤è§„åˆ’
	
	   |                 | hadoop101 | hadoop102 | hadoop103 |
	   | --------------- | --------- | --------- | --------- |
	   | Flume(é‡‡é›†æ—¥å¿—) | Flume     | Flume     |           |
	
	2. å®‰è£…
	
	   å®‰è£…åŒ…å‡†å¤‡ï¼š[apache-flume-1.9.0](http://www.apache.org/dyn/closer.lua/flume/1.9.0/apache-flume-1.9.0-bin.tar.gz)
	
	   ```
	   1. è§£å‹apache-flume-1.7.0-bin.tar.gzåˆ°/opt/module/ç›®å½•ä¸‹
	   2. ä¿®æ”¹apache-flume-1.7.0-binçš„åç§°ä¸ºflume-1.7.0
	   3. å°†flume/confä¸‹çš„flume-env.sh.templateæ–‡ä»¶ä¿®æ”¹ä¸ºflume-env.shï¼Œå¹¶é…ç½®flume-env.shæ–‡ä»¶
	   	export JAVA_HOME=/opt/module/jdk1.8.0_144
	   ```
	
	   
	
	## Sqoop
	
	1. [ä¸‹è½½](https://mirrors.tuna.tsinghua.edu.cn/apache/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz)å¹¶è§£å‹åˆ°æŒ‡å®šç›®å½•
	
	   `$ tar -zxvf sqoop-1.4.7.bin__hadoop-2.0.4-alpha.tar.gz -C /opt/module/`
	
	2. ä¿®æ”¹é…ç½®æ–‡ä»¶
	
	   ```
	   1. é‡å‘½åé…ç½®æ–‡ä»¶
	   	$ cp sqoop-env-template.sh sqoop-env.sh
	   2. ä¿®æ”¹é…ç½®æ–‡ä»¶
	   	vim sqoop-env.sh
	   	export HADOOP_COMMON_HOME=/opt/module/hadoop-2.7.2
	       export HADOOP_MAPRED_HOME=/opt/module/hadoop-2.7.2
	       export HIVE_HOME=/opt/module/hive
	       export ZOOKEEPER_HOME=/opt/module/zookeeper-3.4.10
	       export ZOOCFGDIR=/opt/module/zookeeper-3.4.10/conf
	       export HBASE_HOME=/opt/module/hbase
	   ```
	
	3. æ‹·è´[JDBCé©±åŠ¨](https://dev.mysql.com/downloads/file/?id=480090)
	
	   `$ cp mysql-connector-java-5.1.47-bin.jar /opt/module/sqoop-1.4.6.bin__hadoop-2.0.4-alpha/lib/`
	
	4. éªŒè¯Sqoop
	
	   `bin/sqoop help`
	
	   > å‡ºç°ä¸€äº›Warningè­¦å‘Šï¼ˆè­¦å‘Šä¿¡æ¯å·²çœç•¥ï¼‰ï¼Œå¹¶ä¼´éšç€å¸®åŠ©å‘½ä»¤çš„è¾“å‡ºï¼š
	   >
	   > Available commands:
	   >
	   >   codegen            Generate code to interact with database records
	   >
	   >   create-hive-table     Import a table definition into Hive
	   >
	   >   eval               Evaluate a SQL statement and display the results
	   >
	   >   export             Export an HDFS directory to a database table
	   >
	   >   help               List available commands
	   >
	   >   import             Import a table from a database to HDFS
	   >
	   >   import-all-tables     Import tables from a database to HDFS
	   >
	   >   import-mainframe    Import datasets from a mainframe server to HDFS
	   >
	   >   job                Work with saved jobs
	   >
	   >   list-databases        List available databases on a server
	   >
	   >   list-tables           List available tables in a database
	   >
	   >   merge              Merge results of incremental imports
	   >
	   >   metastore           Run a standalone Sqoop metastore
	   >
	   >   version            Display version information
	
	5. æµ‹è¯•Sqoopè¿æ¥æ•°æ®åº“
	
	   `$ bin/sqoop list-databases --connect jdbc:mysql://hadoop101:3306/ --username root --password mysql`
	
	   > å‡ºç°å¦‚ä¸‹è¾“å‡ºï¼š
	   >
	   > information_schema
	   >
	   > metastore
	   >
	   > mysql
	   >
	   > oozie
	   >
	   > performance_schema
	
	## Hive
	
	1. ### Hiveå®‰è£…é…ç½®
	
	   1. è§£å‹apache-hive-1.2.1-bin.tar.gzåˆ°/opt/module/ç›®å½•
	
	   2. ä¿®æ”¹apache-hive-1.2.1çš„åç§°ä¸ºhive
	
	   3. ä¿®æ”¹/opt/module/hive/confç›®å½•ä¸‹çš„hive-env.sh.templateåç§°ä¸ºhive-env.sh
	
	   4. é…ç½®hive-env.shæ–‡ä»¶
	
	      ```
	      1. é…ç½®HADOOP_HOMEè·¯å¾„
	      	export HADOOP_HOME=/opt/module/hadoop-2.7.2
	      2. é…ç½®HIVE_CONF_DIRè·¯å¾„
	      	export HIVE_CONF_DIR=/opt/module/hive/conf
	      ```
	
	   2. ### Hadoopé›†ç¾¤é…ç½®
	
	      ```
	      1. å¯åŠ¨hdfså’Œyarn
	      2. åœ¨HDFSä¸Šåˆ›å»º/tmpå’Œ/user/hive/warehouseä¸¤ä¸ªç›®å½•å¹¶ä¿®æ”¹ä»–ä»¬çš„åŒç»„æƒé™å¯å†™
	      	hadoop fs -mkdir /tmp
	      	hadoop fs -mkdir -p /user/hive/warehouse
	      	hadoop fs -chmod g+w /tmp
	      	hadoop fs -chmod g+w /user/hive/warehouse
	      ```
	
	   3. ### å®‰è£…MySQL
	
	      1. æŸ¥çœ‹mysqlæ˜¯å¦å®‰è£…ï¼Œå¦‚æœå®‰è£…äº†ï¼Œå¸è½½mysql
	
	         ```
	         1. æŸ¥çœ‹
	         	$ rpm -qa|grep mysql
	         	mysql-libs-5.1.73-8.el6_8.x86_64
	         2. å¸è½½
	         	$ rpm -e --nodeps mysql-libs-5.1.73-8.el6_8.x86_64
	         ```
	
	      2. è¿›å…¥åˆ°mysql-libsæ–‡ä»¶å¤¹
	
	         ```
	         $ ll
	         æ€»ç”¨é‡ 76M
	         -rw-r--r--. 1 msql msql  18M 6æœˆ  29 20:13 MySQL-client-5.6.24-1.el6.x86_64.rpm
	         -rw-r--r--. 1 msql msql 852K 6æœˆ  29 20:13 mysql-connector-java-5.1.27-bin.jar
	         -rw-r--r--. 1 msql msql 3.5M 6æœˆ  29 20:13 mysql-connector-java-5.1.27.tar.gz
	         -rw-r--r--. 1 msql msql  54M 6æœˆ  29 20:13 MySQL-server-5.6.24-1.el6.x86_64.rpm
	         ```
	
	      3. å®‰è£…MySqlæœåŠ¡å™¨
	
	         ```
	         1. å®‰è£…mysqlæœåŠ¡ç«¯
	         	rpm -ivh MySQL-server-5.6.24-1.el6.x86_64.rpm
	         2. æŸ¥çœ‹äº§ç”Ÿçš„éšæœºå¯†ç 
	         	cat /root/.mysql_secret
	         3. æŸ¥çœ‹mysqlçŠ¶æ€
	         	service mysql status
	         4. å¯åŠ¨mysql
	         	service mysql start
	         ```
	
	      4. å®‰è£…å®¢æˆ·ç«¯
	
	         ```
	         1. å®‰è£…mysqlå®¢æˆ·ç«¯
	         	rpm -ivh MySQL-client-5.6.24-1.el6.x86_64.rpm
	         2. é“¾æ¥mysql
	         	mysql -uroot -pOEXaQuS8IWkG19Xs
	         3. ä¿®æ”¹å¯†ç 
	         	mysql>SET PASSWORD=PASSWORD('mysql');
	         4. é€€å‡ºmysql
	         	mysql>exit
	         ```
	
	      5. MySqlä¸­userè¡¨ä¸­ä¸»æœºé…ç½®
	
	         ```
	         1. è¿›å…¥mysql
	         	$ mysql -uroot -pmysql
	         2. æ˜¾ç¤ºæ•°æ®åº“
	         	mysql>show databases;
	         3. ä½¿ç”¨mysqlæ•°æ®åº“
	         	mysql>use mysql;
	         4. æŸ¥è¯¢userè¡¨
	         	mysql>select User, Host, Password from user;
	         5. ä¿®æ”¹userè¡¨ï¼ŒæŠŠHostè¡¨å†…å®¹ä¿®æ”¹ä¸º%
	         	mysql>update user set host='%' where host='localhost';
	         5. åˆ é™¤rootç”¨æˆ·çš„å…¶ä»–host
	         	mysql>delete from user where Host<>'%';
	         6. åˆ·æ–°
	         	mysql>flush privileges;
	         7. é€€å‡º
	         	mysql>quit;
	         ```
	
	      6. Hiveå…ƒæ•°æ®é…ç½®åˆ°MySql
	
	         1. é©±åŠ¨æ‹·è´
	
	            ```
	            1. åœ¨/opt/software/mysql-libsç›®å½•ä¸‹è§£å‹mysql-connector-java-5.1.27.tar.gzé©±åŠ¨åŒ…
	            2. æ‹·è´/opt/software/mysql-libs/mysql-connector-java-5.1.27ç›®å½•ä¸‹çš„mysql-connector-java-5.1.27-bin.jaråˆ°/opt/module/hive/lib/
	            ```
	
	         2. é…ç½®Metastoreåˆ°MySql
	
	            ```xml
	            1. åœ¨/opt/module/hive/confç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªhive-site.xml
	            2. æ ¹æ®å®˜æ–¹æ–‡æ¡£é…ç½®å‚æ•°ï¼Œæ‹·è´æ•°æ®åˆ°hive-site.xmlæ–‡ä»¶ä¸­
	            	<?xml version="1.0"?>
	                <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
	                <configuration>
	                	<property>
	                		<name>javax.jdo.option.ConnectionURL</name>
	                		<value>jdbc:mysql://hadoop102:3306/metastore?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=UTF-8</value>
	                		<description>JDBC connect string for a JDBC metastore</description>
	                	</property>
	                	<property>
	                		<name>javax.jdo.option.ConnectionDriverName</name>
	                		<value>com.mysql.jdbc.Driver</value>
	                		<description>Driver class name for a JDBC metastore</description>
	                	</property>
	                	<property>
	                		<name>javax.jdo.option.ConnectionUserName</name>
	                		<value>root</value>
	                	<description>username to use against metastore database</description>
	                	</property>
	                	<property>
	                		<name>javax.jdo.option.ConnectionPassword</name>
	                		<value>000000</value>
	                		<description>password to use against metastore database</description>
	                	</property>
	                    <property>
	                		<name>hive.cli.print.header</name>
	                		<value>true</value>
	                	</property>
	                    <property>
	                		<name>hive.cli.print.current.db</name>
	                		<value>true</value>
	                	</property>
	                </configuration>
	            ```
	
	
	## Oozie
	
	1. éƒ¨ç½²Hadoopï¼ˆCDHç‰ˆæœ¬ï¼‰
	   1. ä¿®æ”¹Hadoopé…ç½®æ–‡ä»¶
	   2. å¯åŠ¨Hadoopé›†ç¾¤
	2. éƒ¨ç½²Oozie
	   1. 

